{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5babfa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import BPR, Pop\n",
    "from recbole.model.sequential_recommender import SASRec\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "# Set torch.load compatibility\n",
    "torch.serialization.add_safe_globals([dict, list, tuple, set])\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6acdfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Amazon Reviews 2023 Dataset ===\n",
      "Raw dataset loaded, samples: 701528\n",
      "=== Using 5-core Filtering in RecBole ===\n",
      "Creating 5-core filtered dataset...\n",
      "\n",
      "üìä 5-core Filtered Dataset Statistics:\n",
      "Users: 254\n",
      "Items: 357\n",
      "Interactions: 2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  split_point = np.cumsum(feat[field].agg(len))[:-1]\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/sequential_dataset.py:165: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  ].agg(len)\n"
     ]
    }
   ],
   "source": [
    "# Load Amazon Reviews 2023 dataset using RecBole\n",
    "print(\"=== Loading Amazon Reviews 2023 Dataset ===\")\n",
    "\n",
    "# Load raw dataset (optional, for comparison)\n",
    "raw_dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True)\n",
    "print(f\"Raw dataset loaded, samples: {len(raw_dataset['full'])}\")\n",
    "\n",
    "# Âú®RecBole‰∏≠‰ΩøÁî®5-coreËøáÊª§\n",
    "print(\"=== Using 5-core Filtering in RecBole ===\")\n",
    "\n",
    "config_5core = Config(\n",
    "    model='SASRec',\n",
    "    dataset='All_Beauty', \n",
    "    config_dict={\n",
    "        'data_path': 'seq_rec_results/dataset/processed/',\n",
    "        'load_col': {\n",
    "            'inter': ['user_id', 'item_id_list', 'item_id']\n",
    "        },\n",
    "        'benchmark_filename': ['train', 'valid', 'test'],\n",
    "        'alias_of_item_id': ['item_id_list'],\n",
    "        'train_neg_sample_args': None,\n",
    "        'loss_type': 'CE',\n",
    "    }\n",
    ")\n",
    "\n",
    "# ÂàõÂª∫5-coreËøáÊª§ÂêéÁöÑÊï∞ÊçÆÈõÜ\n",
    "print(\"Creating 5-core filtered dataset...\")\n",
    "dataset_5core = create_dataset(config_5core)\n",
    "train_data_5core, valid_data_5core, test_data_5core = data_preparation(config_5core, dataset_5core)\n",
    "\n",
    "print(f\"\\nüìä 5-core Filtered Dataset Statistics:\")\n",
    "print(f\"Users: {dataset_5core.user_num}\")\n",
    "print(f\"Items: {dataset_5core.item_num}\")\n",
    "print(f\"Interactions: {dataset_5core.inter_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c22db084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified training function defined!\n"
     ]
    }
   ],
   "source": [
    "# Define unified model training function\n",
    "def train_model(model_type, dataset_name='All_Beauty', epochs=10, **kwargs):\n",
    "    \"\"\"\n",
    "    Unified function to train recommendation models\n",
    "    \n",
    "    Args:\n",
    "        model_type: Model type ('BPR', 'SASRec', 'Pop')\n",
    "        dataset_name: Dataset name\n",
    "        epochs: Training epochs\n",
    "        **kwargs: Additional model-specific parameters\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing model, trainer, config and results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n=== Training {model_type} Model ===\")\n",
    "    \n",
    "    # Base configuration\n",
    "    base_config = {\n",
    "        'data_path': 'seq_rec_results/dataset/processed/',\n",
    "        'benchmark_filename': ['train', 'valid', 'test'],\n",
    "        'epochs': epochs,\n",
    "        'stopping_step': 10,\n",
    "        'eval_step': 1,\n",
    "        'metrics': ['Recall', 'NDCG'],\n",
    "        'topk': [10, 20],\n",
    "        'valid_metric': 'NDCG@10',\n",
    "        'checkpoint_dir': './checkpoints/',\n",
    "        'show_progress': True\n",
    "    }\n",
    "    \n",
    "    # Model-specific configurations\n",
    "    if model_type == 'BPR':\n",
    "        model_class = BPR\n",
    "        model_config = {\n",
    "            **base_config,\n",
    "            'load_col': {'inter': ['user_id', 'item_id']},\n",
    "            'train_neg_sample_args': {\n",
    "                'distribution': 'uniform',\n",
    "                'sample_num': 1,\n",
    "                'alpha': 1.0,\n",
    "                'dynamic': False,\n",
    "                'candidate_num': 0\n",
    "            },\n",
    "            'loss_type': 'BPR',\n",
    "            'learning_rate': 0.001,\n",
    "            'train_batch_size': 2048,\n",
    "        }\n",
    "        \n",
    "    elif model_type == 'SASRec':\n",
    "        model_class = SASRec\n",
    "        model_config = {\n",
    "            **base_config,\n",
    "            'load_col': {'inter': ['user_id', 'item_id_list', 'item_id']},\n",
    "            'alias_of_item_id': ['item_id_list'],\n",
    "            'train_neg_sample_args': None,\n",
    "            'loss_type': 'CE',\n",
    "            'learning_rate': 0.001,\n",
    "            'train_batch_size': 256,\n",
    "            'max_seq_length': 50,\n",
    "            'hidden_size': 64,\n",
    "            'n_layers': 2,\n",
    "            'n_heads': 2,\n",
    "            'inner_size': 256,\n",
    "            'hidden_dropout_prob': 0.5,\n",
    "            'attn_dropout_prob': 0.5,\n",
    "        }\n",
    "        \n",
    "    elif model_type == 'Pop':\n",
    "        model_class = Pop\n",
    "        model_config = {\n",
    "            **base_config,\n",
    "            'load_col': {'inter': ['user_id', 'item_id']},\n",
    "            'train_neg_sample_args': None,\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    # Merge user-defined parameters\n",
    "    model_config.update(kwargs)\n",
    "    \n",
    "    # Create config and dataset\n",
    "    config = Config(\n",
    "        model=model_type,\n",
    "        dataset=dataset_name,\n",
    "        config_dict=model_config\n",
    "    )\n",
    "    \n",
    "    # Create dataset\n",
    "    model_dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, model_dataset)\n",
    "    \n",
    "    print(f\"{model_type} dataset stats:\")\n",
    "    print(f\"Users: {model_dataset.user_num}\")\n",
    "    print(f\"Items: {model_dataset.item_num}\")\n",
    "    print(f\"Interactions: {model_dataset.inter_num}\")\n",
    "    \n",
    "    # Initialize model and trainer\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    model = model_class(config, model_dataset).to(config['device'])\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "    \n",
    "    print(f\"Training {model_type} model...\")\n",
    "    \n",
    "    # torch.load compatibility settings\n",
    "    original_load = torch.load\n",
    "    def safe_load(*args, **kwargs):\n",
    "        kwargs['weights_only'] = False\n",
    "        return original_load(*args, **kwargs)\n",
    "    torch.load = safe_load\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        best_valid_score, best_valid_result = trainer.fit(\n",
    "            train_data, valid_data, saved=True, show_progress=True\n",
    "        )\n",
    "        \n",
    "        print(f\"{model_type} training completed!\")\n",
    "        print(f\"Best validation result: {best_valid_result}\")\n",
    "        \n",
    "        # Test model\n",
    "        test_result = trainer.evaluate(test_data, load_best_model=True, show_progress=True)\n",
    "        print(f\"{model_type} test result: {test_result}\")\n",
    "        \n",
    "        return {\n",
    "            'model_type': model_type,\n",
    "            'model': model,\n",
    "            'trainer': trainer,\n",
    "            'config': config,\n",
    "            'dataset': model_dataset,\n",
    "            'train_data': train_data,\n",
    "            'valid_data': valid_data,\n",
    "            'test_data': test_data,\n",
    "            'best_valid_result': best_valid_result,\n",
    "            'test_result': test_result\n",
    "        }\n",
    "        \n",
    "    finally:\n",
    "        # Restore original torch.load function\n",
    "        torch.load = original_load\n",
    "\n",
    "print(\"Unified training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5dc546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training All Models with Unified Function ===\n",
      "\n",
      "=== Training Pop Model ===\n",
      "Pop dataset stats:\n",
      "Users: 254\n",
      "Items: 352\n",
      "Interactions: 2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pop model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                            | 0/1 [00:00<?, ?it/s]\u001b[0m/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\u001b[1;35mTrain     0\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 17.91it/s, \u001b[1;33mGPU RAM: 0.00 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 146.25it/s, \u001b[1;33mGPU RAM: 0.00 G/79.14 G\u001b[0m]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop training completed!\n",
      "Best validation result: OrderedDict([('recall@10', 0.0), ('recall@20', 0.0124), ('ndcg@10', 0.0), ('ndcg@20', 0.0033)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 569.22it/s, \u001b[1;33mGPU RAM: 0.00 G/79.14 G\u001b[0m]\u001b[0m\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop test result: OrderedDict([('recall@10', 0.0), ('recall@20', 0.0), ('ndcg@10', 0.0), ('ndcg@20', 0.0)])\n",
      "‚úÖ Pop training successful\n",
      "\n",
      "=== Training BPR Model ===\n",
      "BPR dataset stats:\n",
      "Users: 254\n",
      "Items: 352\n",
      "Interactions: 2282\n",
      "Training BPR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                            | 0/1 [00:00<?, ?it/s]\u001b[0m/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\u001b[1;35mTrain     0\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.27it/s, \u001b[1;33mGPU RAM: 0.00 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 169.93it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     1\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 135.82it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 674.74it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     2\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 141.88it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 661.28it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     3\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 145.66it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 673.54it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     4\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 144.69it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 663.08it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR training completed!\n",
      "Best validation result: OrderedDict([('recall@10', 0.0068), ('recall@20', 0.0317), ('ndcg@10', 0.0039), ('ndcg@20', 0.011)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 576.22it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  split_point = np.cumsum(feat[field].agg(len))[:-1]\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/sequential_dataset.py:165: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  ].agg(len)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR test result: OrderedDict([('recall@10', 0.0), ('recall@20', 0.1111), ('ndcg@10', 0.0), ('ndcg@20', 0.0319)])\n",
      "‚úÖ BPR training successful\n",
      "\n",
      "=== Training SASRec Model ===\n",
      "SASRec dataset stats:\n",
      "Users: 254\n",
      "Items: 357\n",
      "Interactions: 2282\n",
      "Training SASRec model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                            | 0/8 [00:00<?, ?it/s]\u001b[0m/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\u001b[1;35mTrain     0\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 17.19it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 292.10it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     1\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 24.35it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 307.79it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     2\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 23.08it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 309.86it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     3\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 22.93it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 293.95it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     4\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 23.27it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 293.18it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SASRec training completed!\n",
      "Best validation result: OrderedDict([('recall@10', 0.1055), ('recall@20', 0.2109), ('ndcg@10', 0.0393), ('ndcg@20', 0.066)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 312.77it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SASRec test result: OrderedDict([('recall@10', 0.0455), ('recall@20', 0.4091), ('ndcg@10', 0.0196), ('ndcg@20', 0.1104)])\n",
      "‚úÖ SASRec training successful\n",
      "\n",
      "Training completed! Successfully trained 3 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train all models using unified function\n",
    "print(\"=== Training All Models with Unified Function ===\")\n",
    "\n",
    "# Store all model results\n",
    "model_results = {}\n",
    "\n",
    "# Train all three models\n",
    "models_to_train = [\n",
    "    {'model_type': 'Pop', 'epochs': 1},  # Pop model trains quickly\n",
    "    {'model_type': 'BPR', 'epochs': 5},  # BPR model\n",
    "    {'model_type': 'SASRec', 'epochs': 5}  # SASRec model\n",
    "]\n",
    "\n",
    "for model_config in models_to_train:\n",
    "    try:\n",
    "        result = train_model(**model_config)\n",
    "        model_results[model_config['model_type']] = result\n",
    "        print(f\"‚úÖ {model_config['model_type']} training successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {model_config['model_type']} training failed: {str(e)}\")\n",
    "        model_results[model_config['model_type']] = None\n",
    "\n",
    "print(f\"\\nTraining completed! Successfully trained {len([r for r in model_results.values() if r is not None])} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a4c475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                Model Performance Comparison Report\n",
      "======================================================================\n",
      "\n",
      "Metric          | Pop          | BPR          | SASRec      \n",
      "------------------------------------------------------------\n",
      "recall@10       | 0.0000       | 0.0000       | 0.0455      \n",
      "ndcg@10         | 0.0000       | 0.0000       | 0.0196      \n",
      "recall@20       | 0.0000       | 0.1111       | 0.4091      \n",
      "ndcg@20         | 0.0000       | 0.0319       | 0.1104      \n",
      "------------------------------------------------------------\n",
      "\n",
      "üèÜ Best model for each metric:\n",
      "  recall@10: SASRec (0.0455)\n",
      "  ndcg@10: SASRec (0.0196)\n",
      "  recall@20: SASRec (0.4091)\n",
      "  ndcg@20: SASRec (0.1104)\n",
      "\n",
      "üìä Overall model ranking:\n",
      "  1. SASRec: 0.1462 (avg score)\n",
      "  2. BPR: 0.0715 (avg score)\n",
      "  3. Pop: 0.0000 (avg score)\n",
      "\n",
      "üìù Model characteristics:\n",
      "  ‚Ä¢ Pop: Item popularity based, fast training, good for cold start [‚úÖ Success]\n",
      "  ‚Ä¢ BPR: Collaborative filtering, personalized, balanced performance [‚úÖ Success]\n",
      "  ‚Ä¢ SASRec: Sequential recommendation, temporal patterns, rich historical data [‚úÖ Success]\n"
     ]
    }
   ],
   "source": [
    "# Unified model performance comparison and analysis\n",
    "def compare_models(model_results):\n",
    "    \"\"\"Compare all trained models\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"                Model Performance Comparison Report\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Extract test results\n",
    "    results_summary = {}\n",
    "    for model_type, result in model_results.items():\n",
    "        if result is not None:\n",
    "            results_summary[model_type] = result['test_result']\n",
    "        else:\n",
    "            results_summary[model_type] = {}\n",
    "    \n",
    "    # Create comparison table\n",
    "    print(f\"\\n{'Metric':<15}\", end=\"\")\n",
    "    model_names = list(results_summary.keys())\n",
    "    for name in model_names:\n",
    "        print(f\" | {name:<12}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * (15 + 15 * len(model_names)))\n",
    "    \n",
    "    metrics_to_compare = ['recall@10', 'ndcg@10', 'recall@20', 'ndcg@20']\n",
    "    best_scores = {}\n",
    "    \n",
    "    for metric in metrics_to_compare:\n",
    "        print(f\"{metric:<15}\", end=\"\")\n",
    "        metric_values = []\n",
    "        \n",
    "        for model_type in model_names:\n",
    "            value = results_summary[model_type].get(metric, 'N/A')\n",
    "            if value != 'N/A':\n",
    "                print(f\" | {value:<12.4f}\", end=\"\")\n",
    "                metric_values.append((model_type, value))\n",
    "            else:\n",
    "                print(f\" | {'N/A':<12}\", end=\"\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Find best model\n",
    "        if metric_values:\n",
    "            best_model, best_score = max(metric_values, key=lambda x: x[1])\n",
    "            best_scores[metric] = (best_model, best_score)\n",
    "    \n",
    "    print(\"-\" * (15 + 15 * len(model_names)))\n",
    "    \n",
    "    # Analyze best models\n",
    "    print(f\"\\nüèÜ Best model for each metric:\")\n",
    "    for metric, (best_model, best_score) in best_scores.items():\n",
    "        print(f\"  {metric}: {best_model} ({best_score:.4f})\")\n",
    "    \n",
    "    # Overall model ranking\n",
    "    model_scores = {name: [] for name in model_names}\n",
    "    for metric in metrics_to_compare:\n",
    "        for model_type in model_names:\n",
    "            value = results_summary[model_type].get(metric, 0)\n",
    "            if value != 'N/A' and value != 0:\n",
    "                model_scores[model_type].append(value)\n",
    "    \n",
    "    avg_scores = {name: sum(scores)/len(scores) if scores else 0 \n",
    "                  for name, scores in model_scores.items()}\n",
    "    \n",
    "    print(f\"\\nüìä Overall model ranking:\")\n",
    "    sorted_models = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (model, score) in enumerate(sorted_models, 1):\n",
    "        print(f\"  {i}. {model}: {score:.4f} (avg score)\")\n",
    "    \n",
    "    # Model characteristics analysis\n",
    "    print(f\"\\nüìù Model characteristics:\")\n",
    "    model_analysis = {\n",
    "        'Pop': 'Item popularity based, fast training, good for cold start',\n",
    "        'BPR': 'Collaborative filtering, personalized, balanced performance',  \n",
    "        'SASRec': 'Sequential recommendation, temporal patterns, rich historical data'\n",
    "    }\n",
    "    \n",
    "    for model_type in model_names:\n",
    "        if model_type in model_analysis:\n",
    "            status = \"‚úÖ Success\" if model_results[model_type] else \"‚ùå Failed\"\n",
    "            print(f\"  ‚Ä¢ {model_type}: {model_analysis[model_type]} [{status}]\")\n",
    "    \n",
    "    return best_scores, sorted_models\n",
    "\n",
    "# Execute model comparison\n",
    "if model_results:\n",
    "    best_scores, model_ranking = compare_models(model_results)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No model results to compare, please run model training first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe7bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt124",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
