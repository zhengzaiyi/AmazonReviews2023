{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5babfa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import BPR, Pop\n",
    "from recbole.model.sequential_recommender import SASRec\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "# Set torch.load compatibility\n",
    "torch.serialization.add_safe_globals([dict, list, tuple, set])\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6acdfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Amazon Reviews 2023 Dataset ===\n",
      "Raw dataset loaded, samples: 701528\n",
      "=== Using 5-core Filtering in RecBole ===\n",
      "Creating 5-core filtered dataset...\n",
      "\n",
      "üìä 5-core Filtered Dataset Statistics:\n",
      "Users: 254\n",
      "Items: 357\n",
      "Interactions: 2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  split_point = np.cumsum(feat[field].agg(len))[:-1]\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/sequential_dataset.py:165: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  ].agg(len)\n"
     ]
    }
   ],
   "source": [
    "# Load Amazon Reviews 2023 dataset using RecBole\n",
    "print(\"=== Loading Amazon Reviews 2023 Dataset ===\")\n",
    "\n",
    "# Load raw dataset (optional, for comparison)\n",
    "raw_dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True)\n",
    "print(f\"Raw dataset loaded, samples: {len(raw_dataset['full'])}\")\n",
    "\n",
    "# Âú®RecBole‰∏≠‰ΩøÁî®5-coreËøáÊª§\n",
    "print(\"=== Using 5-core Filtering in RecBole ===\")\n",
    "\n",
    "config_5core = Config(\n",
    "    model='SASRec',\n",
    "    dataset='All_Beauty', \n",
    "    config_dict={\n",
    "        'data_path': 'seq_rec_results/dataset/processed/',\n",
    "        'load_col': {\n",
    "            'inter': ['user_id', 'item_id_list', 'item_id']\n",
    "        },\n",
    "        'benchmark_filename': ['train', 'valid', 'test'],\n",
    "        'alias_of_item_id': ['item_id_list'],\n",
    "        'train_neg_sample_args': None,\n",
    "        'loss_type': 'CE',\n",
    "    }\n",
    ")\n",
    "\n",
    "# ÂàõÂª∫5-coreËøáÊª§ÂêéÁöÑÊï∞ÊçÆÈõÜ\n",
    "print(\"Creating 5-core filtered dataset...\")\n",
    "dataset_5core = create_dataset(config_5core)\n",
    "train_data_5core, valid_data_5core, test_data_5core = data_preparation(config_5core, dataset_5core)\n",
    "\n",
    "print(f\"\\nüìä 5-core Filtered Dataset Statistics:\")\n",
    "print(f\"Users: {dataset_5core.user_num}\")\n",
    "print(f\"Items: {dataset_5core.item_num}\")\n",
    "print(f\"Interactions: {dataset_5core.inter_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c22db084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified training function defined!\n"
     ]
    }
   ],
   "source": [
    "# Define unified model training function\n",
    "def train_model(model_type, dataset_name='All_Beauty', epochs=10, **kwargs):\n",
    "    \"\"\"\n",
    "    Unified function to train recommendation models\n",
    "    \n",
    "    Args:\n",
    "        model_type: Model type ('BPR', 'SASRec', 'Pop')\n",
    "        dataset_name: Dataset name\n",
    "        epochs: Training epochs\n",
    "        **kwargs: Additional model-specific parameters\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing model, trainer, config and results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n=== Training {model_type} Model ===\")\n",
    "    \n",
    "    # Base configuration\n",
    "    base_config = {\n",
    "        'data_path': 'seq_rec_results/dataset/processed/',\n",
    "        'benchmark_filename': ['train', 'valid', 'test'],\n",
    "        'epochs': epochs,\n",
    "        'stopping_step': 10,\n",
    "        'eval_step': 1,\n",
    "        'metrics': ['Recall', 'NDCG'],\n",
    "        'topk': [10, 20],\n",
    "        'valid_metric': 'NDCG@10',\n",
    "        'checkpoint_dir': './checkpoints/',\n",
    "        'show_progress': True\n",
    "    }\n",
    "    \n",
    "    # Model-specific configurations\n",
    "    if model_type == 'BPR':\n",
    "        model_class = BPR\n",
    "        model_config = {\n",
    "            **base_config,\n",
    "            'load_col': {'inter': ['user_id', 'item_id']},\n",
    "            'train_neg_sample_args': {\n",
    "                'distribution': 'uniform',\n",
    "                'sample_num': 1,\n",
    "                'alpha': 1.0,\n",
    "                'dynamic': False,\n",
    "                'candidate_num': 0\n",
    "            },\n",
    "            'loss_type': 'BPR',\n",
    "            'learning_rate': 0.001,\n",
    "            'train_batch_size': 2048,\n",
    "        }\n",
    "        \n",
    "    elif model_type == 'SASRec':\n",
    "        model_class = SASRec\n",
    "        model_config = {\n",
    "            **base_config,\n",
    "            'load_col': {'inter': ['user_id', 'item_id_list', 'item_id']},\n",
    "            'alias_of_item_id': ['item_id_list'],\n",
    "            'train_neg_sample_args': None,\n",
    "            'loss_type': 'CE',\n",
    "            'learning_rate': 0.001,\n",
    "            'train_batch_size': 256,\n",
    "            'max_seq_length': 50,\n",
    "            'hidden_size': 64,\n",
    "            'n_layers': 2,\n",
    "            'n_heads': 2,\n",
    "            'inner_size': 256,\n",
    "            'hidden_dropout_prob': 0.5,\n",
    "            'attn_dropout_prob': 0.5,\n",
    "        }\n",
    "        \n",
    "    elif model_type == 'Pop':\n",
    "        model_class = Pop\n",
    "        model_config = {\n",
    "            **base_config,\n",
    "            'load_col': {'inter': ['user_id', 'item_id']},\n",
    "            'train_neg_sample_args': None,\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    # Merge user-defined parameters\n",
    "    model_config.update(kwargs)\n",
    "    \n",
    "    # Create config and dataset\n",
    "    config = Config(\n",
    "        model=model_type,\n",
    "        dataset=dataset_name,\n",
    "        config_dict=model_config\n",
    "    )\n",
    "    \n",
    "    # Create dataset\n",
    "    model_dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, model_dataset)\n",
    "    \n",
    "    print(f\"{model_type} dataset stats:\")\n",
    "    print(f\"Users: {model_dataset.user_num}\")\n",
    "    print(f\"Items: {model_dataset.item_num}\")\n",
    "    print(f\"Interactions: {model_dataset.inter_num}\")\n",
    "    \n",
    "    # Initialize model and trainer\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    model = model_class(config, model_dataset).to(config['device'])\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "    \n",
    "    print(f\"Training {model_type} model...\")\n",
    "    \n",
    "    # torch.load compatibility settings\n",
    "    original_load = torch.load\n",
    "    def safe_load(*args, **kwargs):\n",
    "        kwargs['weights_only'] = False\n",
    "        return original_load(*args, **kwargs)\n",
    "    torch.load = safe_load\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        best_valid_score, best_valid_result = trainer.fit(\n",
    "            train_data, valid_data, saved=True, show_progress=True\n",
    "        )\n",
    "        \n",
    "        print(f\"{model_type} training completed!\")\n",
    "        print(f\"Best validation result: {best_valid_result}\")\n",
    "        \n",
    "        # Test model\n",
    "        test_result = trainer.evaluate(test_data, load_best_model=True, show_progress=True)\n",
    "        print(f\"{model_type} test result: {test_result}\")\n",
    "        \n",
    "        return {\n",
    "            'model_type': model_type,\n",
    "            'model': model,\n",
    "            'trainer': trainer,\n",
    "            'config': config,\n",
    "            'dataset': model_dataset,\n",
    "            'train_data': train_data,\n",
    "            'valid_data': valid_data,\n",
    "            'test_data': test_data,\n",
    "            'best_valid_result': best_valid_result,\n",
    "            'test_result': test_result\n",
    "        }\n",
    "        \n",
    "    finally:\n",
    "        # Restore original torch.load function\n",
    "        torch.load = original_load\n",
    "\n",
    "print(\"Unified training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5dc546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training All Models with Unified Function ===\n",
      "\n",
      "=== Training Pop Model ===\n",
      "Pop dataset stats:\n",
      "Users: 254\n",
      "Items: 352\n",
      "Interactions: 2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pop model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                            | 0/1 [00:00<?, ?it/s]\u001b[0m/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\u001b[1;35mTrain     0\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 17.91it/s, \u001b[1;33mGPU RAM: 0.00 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 146.25it/s, \u001b[1;33mGPU RAM: 0.00 G/79.14 G\u001b[0m]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop training completed!\n",
      "Best validation result: OrderedDict([('recall@10', 0.0), ('recall@20', 0.0124), ('ndcg@10', 0.0), ('ndcg@20', 0.0033)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 569.22it/s, \u001b[1;33mGPU RAM: 0.00 G/79.14 G\u001b[0m]\u001b[0m\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop test result: OrderedDict([('recall@10', 0.0), ('recall@20', 0.0), ('ndcg@10', 0.0), ('ndcg@20', 0.0)])\n",
      "‚úÖ Pop training successful\n",
      "\n",
      "=== Training BPR Model ===\n",
      "BPR dataset stats:\n",
      "Users: 254\n",
      "Items: 352\n",
      "Interactions: 2282\n",
      "Training BPR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                            | 0/1 [00:00<?, ?it/s]\u001b[0m/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\u001b[1;35mTrain     0\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.27it/s, \u001b[1;33mGPU RAM: 0.00 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 169.93it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     1\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 135.82it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 674.74it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     2\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 141.88it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 661.28it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     3\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 145.66it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 673.54it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     4\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 144.69it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 663.08it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR training completed!\n",
      "Best validation result: OrderedDict([('recall@10', 0.0068), ('recall@20', 0.0317), ('ndcg@10', 0.0039), ('ndcg@20', 0.011)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 576.22it/s, \u001b[1;33mGPU RAM: 0.02 G/79.14 G\u001b[0m]\u001b[0m\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[field].fillna(value=\"\", inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  split_point = np.cumsum(feat[field].agg(len))[:-1]\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/data/dataset/sequential_dataset.py:165: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  ].agg(len)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR test result: OrderedDict([('recall@10', 0.0), ('recall@20', 0.1111), ('ndcg@10', 0.0), ('ndcg@20', 0.0319)])\n",
      "‚úÖ BPR training successful\n",
      "\n",
      "=== Training SASRec Model ===\n",
      "SASRec dataset stats:\n",
      "Users: 254\n",
      "Items: 357\n",
      "Interactions: 2282\n",
      "Training SASRec model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                            | 0/8 [00:00<?, ?it/s]\u001b[0m/home/sjc4fq/.conda/envs/pt124/lib/python3.11/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\u001b[1;35mTrain     0\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 17.19it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 292.10it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     1\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 24.35it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 307.79it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     2\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 23.08it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 309.86it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     3\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 22.93it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 293.95it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mTrain     4\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 23.27it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n",
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 293.18it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SASRec training completed!\n",
      "Best validation result: OrderedDict([('recall@10', 0.1055), ('recall@20', 0.2109), ('ndcg@10', 0.0393), ('ndcg@20', 0.066)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 312.77it/s, \u001b[1;33mGPU RAM: 0.35 G/79.14 G\u001b[0m]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SASRec test result: OrderedDict([('recall@10', 0.0455), ('recall@20', 0.4091), ('ndcg@10', 0.0196), ('ndcg@20', 0.1104)])\n",
      "‚úÖ SASRec training successful\n",
      "\n",
      "Training completed! Successfully trained 3 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train all models using unified function\n",
    "print(\"=== Training All Models with Unified Function ===\")\n",
    "\n",
    "# Store all model results\n",
    "model_results = {}\n",
    "\n",
    "# Train all three models\n",
    "models_to_train = [\n",
    "    {'model_type': 'Pop', 'epochs': 1},  # Pop model trains quickly\n",
    "    {'model_type': 'BPR', 'epochs': 5},  # BPR model\n",
    "    {'model_type': 'SASRec', 'epochs': 5}  # SASRec model\n",
    "]\n",
    "\n",
    "for model_config in models_to_train:\n",
    "    try:\n",
    "        result = train_model(**model_config)\n",
    "        model_results[model_config['model_type']] = result\n",
    "        print(f\"‚úÖ {model_config['model_type']} training successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {model_config['model_type']} training failed: {str(e)}\")\n",
    "        model_results[model_config['model_type']] = None\n",
    "\n",
    "print(f\"\\nTraining completed! Successfully trained {len([r for r in model_results.values() if r is not None])} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a4c475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                Model Performance Comparison Report\n",
      "======================================================================\n",
      "\n",
      "Metric          | Pop          | BPR          | SASRec      \n",
      "------------------------------------------------------------\n",
      "recall@10       | 0.0000       | 0.0000       | 0.0455      \n",
      "ndcg@10         | 0.0000       | 0.0000       | 0.0196      \n",
      "recall@20       | 0.0000       | 0.1111       | 0.4091      \n",
      "ndcg@20         | 0.0000       | 0.0319       | 0.1104      \n",
      "------------------------------------------------------------\n",
      "\n",
      "üèÜ Best model for each metric:\n",
      "  recall@10: SASRec (0.0455)\n",
      "  ndcg@10: SASRec (0.0196)\n",
      "  recall@20: SASRec (0.4091)\n",
      "  ndcg@20: SASRec (0.1104)\n",
      "\n",
      "üìä Overall model ranking:\n",
      "  1. SASRec: 0.1462 (avg score)\n",
      "  2. BPR: 0.0715 (avg score)\n",
      "  3. Pop: 0.0000 (avg score)\n",
      "\n",
      "üìù Model characteristics:\n",
      "  ‚Ä¢ Pop: Item popularity based, fast training, good for cold start [‚úÖ Success]\n",
      "  ‚Ä¢ BPR: Collaborative filtering, personalized, balanced performance [‚úÖ Success]\n",
      "  ‚Ä¢ SASRec: Sequential recommendation, temporal patterns, rich historical data [‚úÖ Success]\n"
     ]
    }
   ],
   "source": [
    "# Unified model performance comparison and analysis\n",
    "def compare_models(model_results):\n",
    "    \"\"\"Compare all trained models\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"                Model Performance Comparison Report\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Extract test results\n",
    "    results_summary = {}\n",
    "    for model_type, result in model_results.items():\n",
    "        if result is not None:\n",
    "            results_summary[model_type] = result['test_result']\n",
    "        else:\n",
    "            results_summary[model_type] = {}\n",
    "    \n",
    "    # Create comparison table\n",
    "    print(f\"\\n{'Metric':<15}\", end=\"\")\n",
    "    model_names = list(results_summary.keys())\n",
    "    for name in model_names:\n",
    "        print(f\" | {name:<12}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * (15 + 15 * len(model_names)))\n",
    "    \n",
    "    metrics_to_compare = ['recall@10', 'ndcg@10', 'recall@20', 'ndcg@20']\n",
    "    best_scores = {}\n",
    "    \n",
    "    for metric in metrics_to_compare:\n",
    "        print(f\"{metric:<15}\", end=\"\")\n",
    "        metric_values = []\n",
    "        \n",
    "        for model_type in model_names:\n",
    "            value = results_summary[model_type].get(metric, 'N/A')\n",
    "            if value != 'N/A':\n",
    "                print(f\" | {value:<12.4f}\", end=\"\")\n",
    "                metric_values.append((model_type, value))\n",
    "            else:\n",
    "                print(f\" | {'N/A':<12}\", end=\"\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Find best model\n",
    "        if metric_values:\n",
    "            best_model, best_score = max(metric_values, key=lambda x: x[1])\n",
    "            best_scores[metric] = (best_model, best_score)\n",
    "    \n",
    "    print(\"-\" * (15 + 15 * len(model_names)))\n",
    "    \n",
    "    # Analyze best models\n",
    "    print(f\"\\nüèÜ Best model for each metric:\")\n",
    "    for metric, (best_model, best_score) in best_scores.items():\n",
    "        print(f\"  {metric}: {best_model} ({best_score:.4f})\")\n",
    "    \n",
    "    # Overall model ranking\n",
    "    model_scores = {name: [] for name in model_names}\n",
    "    for metric in metrics_to_compare:\n",
    "        for model_type in model_names:\n",
    "            value = results_summary[model_type].get(metric, 0)\n",
    "            if value != 'N/A' and value != 0:\n",
    "                model_scores[model_type].append(value)\n",
    "    \n",
    "    avg_scores = {name: sum(scores)/len(scores) if scores else 0 \n",
    "                  for name, scores in model_scores.items()}\n",
    "    \n",
    "    print(f\"\\nüìä Overall model ranking:\")\n",
    "    sorted_models = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (model, score) in enumerate(sorted_models, 1):\n",
    "        print(f\"  {i}. {model}: {score:.4f} (avg score)\")\n",
    "    \n",
    "    # Model characteristics analysis\n",
    "    print(f\"\\nüìù Model characteristics:\")\n",
    "    model_analysis = {\n",
    "        'Pop': 'Item popularity based, fast training, good for cold start',\n",
    "        'BPR': 'Collaborative filtering, personalized, balanced performance',  \n",
    "        'SASRec': 'Sequential recommendation, temporal patterns, rich historical data'\n",
    "    }\n",
    "    \n",
    "    for model_type in model_names:\n",
    "        if model_type in model_analysis:\n",
    "            status = \"‚úÖ Success\" if model_results[model_type] else \"‚ùå Failed\"\n",
    "            print(f\"  ‚Ä¢ {model_type}: {model_analysis[model_type]} [{status}]\")\n",
    "    \n",
    "    return best_scores, sorted_models\n",
    "\n",
    "# Execute model comparison\n",
    "if model_results:\n",
    "    best_scores, model_ranking = compare_models(model_results)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No model results to compare, please run model training first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe7bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3ec8cb0",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e5aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "meta_data = json.load(open('seq_rec_results/dataset/processed/All_Beauty/All_Beauty.data_maps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a18a96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzheng3/miniconda3/envs/rs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "datasets = load_dataset(\n",
    "    \"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "    f\"5core_timestamp_w_his_All_Beauty\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34decd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701528it [00:07, 94219.01it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "review_list = []\n",
    "with open('seq_rec_results/dataset/processed/All_Beauty/All_Beauty.jsonl', 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        review_list.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd9f5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_set = set(meta_data['user2id'].keys())\n",
    "item_set = set(meta_data['item2id'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4fb4dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rating': 5.0,\n",
       " 'title': 'Such a lovely scent but not overpowering.',\n",
       " 'text': \"This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want. I have a lot of hair, medium thickness. I am comparing to other brands with yucky chemicals so I'm gonna stick with this. Try it!\",\n",
       " 'images': [],\n",
       " 'asin': 'B00YQ6X8EO',\n",
       " 'parent_asin': 'B00YQ6X8EO',\n",
       " 'user_id': 'AGKHLEW2SOWHNMFQIJGBECAF7INQ',\n",
       " 'timestamp': 1588687728923,\n",
       " 'helpful_vote': 0,\n",
       " 'verified_purchase': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "user2reviews = defaultdict(list)\n",
    "for review in review_list:\n",
    "    if review['user_id'] in user_set and review['asin'] in item_set:\n",
    "        user2reviews[review['user_id']].append({\n",
    "            'rating': review['rating'],\n",
    "            'title': review['title'],\n",
    "            'text': review['text'],\n",
    "            'item_id': meta_data['item2id'][review['asin']],\n",
    "            'timestamp': review['timestamp'],\n",
    "            'helpful_vote': review['helpful_vote'],\n",
    "            'verified_purchase': review['verified_purchase'],\n",
    "        })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f962d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save user2reviews\n",
    "with open('seq_rec_results/dataset/processed/All_Beauty/All_Beauty.reviews', 'w') as f:\n",
    "    json.dump(user2reviews, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ce8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfd9139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:12<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "import outlines\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "model = outlines.from_transformers(\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\"),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11107f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: excellent\n",
      "Pros: ['long battery life', 'stunning display', 'portable']\n",
      "Summary: The Dell XPS 13 is a solid laptop that excels in battery life and display quality, but it has some drawbacks that prevent it from being a top contender in its class.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "\n",
    "class Rating(Enum):\n",
    "    poor = 1\n",
    "    fair = 2\n",
    "    good = 3\n",
    "    excellent = 4\n",
    "\n",
    "class ProductReview(BaseModel):\n",
    "    rating: Rating\n",
    "    pros: list[str]\n",
    "    cons: list[str]\n",
    "    summary: str\n",
    "\n",
    "review = model(\n",
    "    \"Review: The XPS 13 has great battery life and a stunning display, but it runs hot and the webcam is poor quality.\",\n",
    "    ProductReview,\n",
    "    max_new_tokens=200,\n",
    ")\n",
    "\n",
    "review = ProductReview.model_validate_json(review)\n",
    "print(f\"Rating: {review.rating.name}\")  # \"Rating: good\"\n",
    "print(f\"Pros: {review.pros}\")           # \"Pros: ['great battery life', 'stunning display']\"\n",
    "print(f\"Summary: {review.summary}\")     # \"Summary: Good laptop with great display but thermal issues\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9477de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzheng3/miniconda3/envs/rs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-16 21:20:04 [__init__.py:241] Automatically detected platform cuda.\n",
      "INFO 09-16 21:20:05 [utils.py:326] non-default args: {'model': 'Qwen/Qwen2.5-3B-Instruct', 'max_model_len': 100, 'disable_log_stats': True}\n",
      "INFO 09-16 21:20:15 [__init__.py:711] Resolved architecture: Qwen2ForCausalLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-16 21:20:15 [__init__.py:1750] Using max model len 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 21:20:15,896\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-16 21:20:16 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:18 [core.py:636] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:18 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='Qwen/Qwen2.5-3B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=100, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen2.5-3B-Instruct, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:23 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m WARNING 09-16 21:20:23 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:23 [gpu_model_runner.py:1953] Starting to load model Qwen/Qwen2.5-3B-Instruct...\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:23 [gpu_model_runner.py:1985] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:23 [cuda.py:328] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:23 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:56 [weight_utils.py:312] Time spent downloading weights for Qwen/Qwen2.5-3B-Instruct: 32.415442 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.45it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01it/s]\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:58 [default_loader.py:262] Loading weights took 2.10 seconds\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:20:59 [gpu_model_runner.py:2007] Model loading took 5.7916 GiB and 35.112943 seconds\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:21:11 [backends.py:548] Using cache directory: /home/zzheng3/.cache/vllm/torch_compile_cache/0a9ab1607d/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:21:11 [backends.py:559] Dynamo bytecode transform time: 12.01 s\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:21:17 [backends.py:194] Cache the graph for dynamic shape for later use\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:21:54 [backends.py:215] Compiling a graph for dynamic shape takes 40.86 s\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:22:10 [monitor.py:34] torch.compile takes 52.87 s in total\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:22:12 [gpu_worker.py:276] Available KV cache memory: 64.10 GiB\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:22:12 [kv_cache_utils.py:849] GPU KV cache size: 1,867,008 tokens\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:22:12 [kv_cache_utils.py:853] Maximum concurrency for 100 tokens per request: 16669.71x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:03<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:22:16 [gpu_model_runner.py:2708] Graph capturing finished in 4 secs, took 0.57 GiB\n",
      "\u001b[1;36m(EngineCore_0 pid=1621821)\u001b[0;0m INFO 09-16 21:22:16 [core.py:214] init engine (profile, create kv cache, warmup model) took 77.61 seconds\n",
      "INFO 09-16 21:22:18 [llm.py:298] Supported_tasks: ['generate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 37.90it/s]\n",
      "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.96s/it, est. speed input: 24.55 toks/s, output: 25.57 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex-constrained output:\n",
      "\"\n",
      "\n",
      " \n",
      "   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 552.46it/s]\n",
      "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.62it/s, est. speed input: 65.61 toks/s, output: 105.69 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON-schema-constrained output:\n",
      "{\"name\": \"Isaac Newton\", \"age\": 46, \"email\": \"isaac.newton@cam.ac.uk\"}\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.sampling_params import GuidedDecodingParams\n",
    "\n",
    "# ÂÆö‰πâ JSON schema via Pydantic Ê®°Âûã\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    email: str\n",
    "\n",
    "json_schema = Person.model_json_schema()\n",
    "\n",
    "def main():\n",
    "    llm = LLM(model=\"Qwen/Qwen2.5-3B-Instruct\", max_model_len=100)\n",
    "\n",
    "    # ‰ΩøÁî® regex Âº∫Âà∂ËæìÂá∫ÂΩ¢ÂºèÔºå‰æãÂ¶Ç email Ê†ºÂºè\n",
    "    guided_regex = r'\"\\s*email\"\\s*:\\s*\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\"'\n",
    "    guided_decoding_params_regex = GuidedDecodingParams(regex=guided_regex)\n",
    "    sampling_params_regex = SamplingParams(\n",
    "        guided_decoding=guided_decoding_params_regex,\n",
    "        max_tokens=50\n",
    "    )\n",
    "\n",
    "    prompt_regex = (\n",
    "        \"Generate a JSON object with fields name, age, and email about a scientist:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"name\": \"Ada Lovelace\",\\n'\n",
    "        '  \"age\": 36,\\n'\n",
    "        '  \"email\": \"ada.lovelace@example.com\"\\n'\n",
    "        \"}\"\n",
    "    )\n",
    "\n",
    "    out_regex = llm.generate(prompts=prompt_regex, sampling_params=sampling_params_regex)\n",
    "    print(\"Regex-constrained output:\")\n",
    "    print(out_regex[0].outputs[0].text)\n",
    "\n",
    "    # ‰ΩøÁî® JSON schema Âº∫Âà∂ËæìÂá∫Êï¥‰∏™ÁªìÊûÑÁ¨¶Âêà Person Ê®°Âûã\n",
    "    guided_decoding_params_json = GuidedDecodingParams(json=json_schema)\n",
    "    sampling_params_json = SamplingParams(\n",
    "        guided_decoding=guided_decoding_params_json,\n",
    "        max_tokens=100\n",
    "    )\n",
    "\n",
    "    prompt_json = (\n",
    "        \"Generate a JSON object about a historical scientist with name, age (integer), and email.\"\n",
    "    )\n",
    "\n",
    "    out_json = llm.generate(prompts=prompt_json, sampling_params=sampling_params_json)\n",
    "    print(\"JSON-schema-constrained output:\")\n",
    "    print(out_json[0].outputs[0].text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16cb79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
